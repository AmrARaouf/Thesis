\documentclass[12pt, a4paper, fleqn]{memoir}%makeidx

%******************************************************************************
% STYLE
%******************************************************************************
\input{style.tex}

%******************************************************************************
% BEGIN DOCUMENT
%******************************************************************************
\begin{document}

%******************************************************************************
% FRONT MATTER
%******************************************************************************
\frontmatter

%******************************************************************************
% EMPTY PAGE
%******************************************************************************
\pagestyle{empty}
This is actually the first page of the thesis and will be discarded after the print out. This is done because 
the title page has to be an even page. The memoir style package used by this template makes different indentations 
for odd and even pages which is usally done for better readability.  
\clearpage

%******************************************************************************
% TITLE PAGE
%******************************************************************************
\pagestyle{empty}
\rmfamily
\noindent
\begin{center}
University of Augsburg\\
Faculty of Applied Computer Science\\
Department of Computer Science\\
Bachelor's Program in Computer Science\\
\end{center}
\begin{figure}[h]
\centering
\includegraphics[width=0.25\textwidth]{logo.png}
\end{figure}
\vfill\vfill
\begin{center}
\Large
Bachelor's Thesis\\
\end{center}
\vspace{2.0em}
\begin{center}
\Large
\LARGE Engagement Detection\\ \vspace{10pt} 
\Large Inferring conversational engagement from nonverbal behaviour
\end{center}
\vspace{2.0em}
\begin{center}
    \normalsize
    submitted by\\
    \large
    Amr Abdelraouf\\
    \normalsize
    on 31.7.2014
\end{center}
\vspace{2.0em}
\begin{center}
    \normalsize
    Supervisor:\\ 
    Prof. Dr. Elisabeth Andr\'{e} aus Augsburg
\end{center}
\begin{center}
    \normalsize
    Adviser:\\
    MSc. Tobias Baur
\end{center}
\begin{center}
    \normalsize
    Reviewers:\\
    Prof. Dr. Elisabeth Andr\'{e}\\
\end{center}
\cleardoublepage

%******************************************************************************
% ABSTRACT
%******************************************************************************
\chapter*{Abstract}
Interview skills are of utmost important for a person's career and personal image. Furthermore it is an essential matter to exhude conversational engagement in an interview to give the impression of confidence and attentiveness. This thesis aims to track the engagment level of an interviewee in a mock interview situation. It tracks the verbal and nonverbal behaviour of the interviewee with respect to the ongoing context of the interview. The gathered engagement data can be further used to assess the interviewee's performence.

%******************************************************************************
% STATEMENT & DECLARATION
%******************************************************************************
\chapter*{Statement and Declaration of Consent}
\vfill
\subsubsection*{\LARGE Statement}
Hereby I confirm that this thesis is my own work and that I have documented all sources used.
\vfill
\begin{flushleft}
Amr Abdelraouf
\end{flushleft}  
\begin{flushright}
Augsburg, 3.7.2014 
\end{flushright}
\vfill
\vfill
\subsubsection*{\LARGE Declaration of Consent}
Herewith I agree that my thesis will be made available through the library of the Computer Science Department.
\vfill
\begin{flushleft}
Amr Abdelraouf
\end{flushleft}  
\begin{flushright}
Augsburg, 3.7.2014 
\end{flushright}
\vfill

%******************************************************************************
% TABLE OF CONTENTS
%******************************************************************************
\cleardoublepage
\rmfamily
\normalfont
\pagenumbering{roman}
\pagestyle{headings}
\tableofcontents


%******************************************************************************
% MAIN MATTER
%******************************************************************************
\mainmatter

%##########################################################
\chapter{Introduction}
\label{chap:Introduction}

\section{Motivation}
\label{sec:Motivation}
This thesis was proposed to help measure the engagement of an interviewee in a job interview situation. Through a simple mock interview the interviewee will be assessed on his/her performence. One of the most important attributes of that performence is whether or not s/he is engaged with and attentive to the interviewer. A simple playback of his/her performence coupled with the measurment of his/her engagement level will easily highlight weak spots in the mock interview.

\section{Objectives}
\label{sec:Objectives}
This thesis aims to measure the engagement levels of an interviewee through non verbal behaviour of said interview. It studies the conversational interaction with the interviewer, the responses to certain commands, his/her behaviour during certain segments of the interview.

\section{Outline}
\label{sec:Outline}
FEL A5ER

%##########################################################
\chapter{Theoretical Background}
\label{chap:TheoreticalBackground}

\section{Setup}
\label{sec:Section}

\subsection{Subject}
The subject of our expirament is the interviewee in our mock interview. As shown in figure \ref{fig:setup_img} the subject is seated aproximately 70 cm from a screen. The subject is asked to adjust to a number of sensors: a Microsoft Kinekt camera, an SMI Eyetracker and a microphone.

\subsection{Agent}
\label{subsec:Agent}
The agent in our expirament is a reference to the interviewer. The agent is simulated by Scenemaker: a software that is used to create a virtual environment and virtual characters that follow a written script. This script contains verbal utterences, gestures, and commands to wait for a reply from the subject. The main scene used contains two virtual agents named Curtis and Gloria who are standing behind a desk to mimic an office interview. On the left lies a white board that is used as an object in our script.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{setup}
    \caption{Interview setup}
    \label{fig:setup_img}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{agents}
    \caption{Virtual agents}
    \label{fig:image_img}
\end{figure}

%%##########################################################
\chapter{Events}
\label{chap:Events}
Events are the backbone of the software workings of this thesis. Raw sensor data are converted to events that can be further processed in the software's pipeline. Furthermore external software send events to our own software over a network. These events can be displayed by themselves as output or can be used as inputs to trigger other events.

\section{Event Structure}
Events are constructs of several attributes:

\begin{description}
  \item[Time] The clock signature of when the event was triggered.
  \item[Duration] The time duration of the event.
  \item[Ptr] Meta data about the event.
  \item[Type] Indicates the nature of the meta data wrapped by the event.
\end{description}

\section{Sensors}
\label{sec:Sensors}

\subsection{Microsoft Kinekt}
Kinekt sensors are used to track the skeletal movements of a subject. However in this module we are mainly interested in the movement of the subject's head. Kinekt is used to detect the prepetual displacement of the subject's head which indicates that s/he is nodding. This triggers an event called \textit{HeadNod}. HeadNod is an event measured every 500 ms and its pointer contains a value from 0 to 1 which represents the probability that the subject is nodding his/her head.

\subsection{SMI Eyetracker}
The SMI Eyetracker is used to pinpoint where the subject is currently looking. Since we are dealing with a virtual agent on a screen we consider the top left corner of the screen as the (0,0) coordinate. Displacement to the right and bottom of the looking point on the screen change the values of the x and y coordinates respectively.

The software defines two main areas on the screen. First is the area of the Agent's face. Second is the area of the board that is present in the environment.

When the subject's looking point falls on the area defined for the agent's face it triggers an event called \textit{SubjectFacialGaze}. SubjectFacialGaze's pointer contains a value of either 0 or 1 indicating whether or not the subject is looking at the agent's face. When the gaze enters the facial area SubjectFacialGaze is triggered with the value 1 indicating that it has started and when the gaze leaves the facial area it is triggered with the value 0 indicating that it is complete.

If the subject's gaze falls in the area of the board the event \textit{SubjectObjectGaze} is triggered. Similar to SubjectFacialGaze, the event carries a value of either 0 or 1 indicating whether or not the subject is looking at the board, value 1 when it starts and value 0 when it ends.

\subsection{Microphone}
A microphone is used to record the verbal utterances produced by the subject. When the microphone detects a voice the event \textit{vad} (which is short for..) is fired. When the voice is first detected the event's pointer carries a value of 1. When the voice activity ends the same event is triggered but with value 0 to indicate that the event is complete.

\section{Scenemaker}
\label{sec:Scenemaker}
As mentioned before in subsection \ref{subsec:Agent} Scenemaker is the softawre used to simulate the interview environment and create the virtual agents. Scenemaker is also responsible for sending the events that are triggered to represent the agents' behaviour to our software's pipeline. The events can be subcategorized into two main parts: Gaze and speech.

\subsection{Gaze}
Firstly we are concerned with where the agent is looking. When the script commands the agent to looks at the subject in front of the screen the event \textit{AgentSubjectGaze} is triggered. Similar to the subject's gaze events the event pointer holds the value 1 when the agent starts looking at the subject and holds the value 0 when the agent looks away from the subject's face.
Furthermore when the agent is commanded to look at the board the event \textit{AgentObjectGaze} is triggered with a pointer value 1 or 0 indicating that the agent has started or stopped looking at the board.

\subsection{Speech}
The agent utters the sentences that are written in the affiliated script. When the agent starts reading a sentence the event \textit{AgentSpeech} is triggered with a pointer value of 1. When the agent finishes reading that sentence AgentSpeech is triggered witha pointer value of 0.

%%##########################################################
\chapter{Main Modules}
\label{chap:MainModules}

\section{Mutual Facial Gaze}
\label{sec:MutualFacialGaze}

\section{Directed Gaze}
\label{sec:DirectedGaze}

\section{Adjacency Pair}
\label{sec:AdjacencyPair}

\section{Bachchanneling}
\label{sec:Bachchanneling}

%%##########################################################
\chapter{Bayesian Network}
\label{chap:BayesianNetwork}

%%##########################################################
\chapter{Summery}
\label{Summery}

%******************************************************************************
% BIBLIOGRAPHY
%******************************************************************************
\bibliographystyle{plain}
{\small\bibliography{master}}

%******************************************************************************
% APPENDIX
%******************************************************************************
\appendix
\appendixpage*
\chapter{First Appendix}

%******************************************************************************
% BACK MATTER
%******************************************************************************
\backmatter

%******************************************************************************
% LIST OF SYMBOLS
%******************************************************************************
%\normalfont
%\clearpage
%\chapter[List of Symbols and Abbreviations]{List of Symbols and Abbreviations}
%\begin{center}
%\small
%\begin{longtable}{lp{3.0in}c}
%\toprule
%\multicolumn{1}{c}{Abbreviation} & \multicolumn{1}{c}{Description}\\ \midrule\addlinespace[2pt] \endhead
%\bottomrule\endfoot
%XML & E\textbf{X}tensible \textbf{M}arkup \textbf{L}anguage \\
%XSD & \textbf{X}ML-\textbf{S}chema-\textbf{D}efinition \\
%SFXML & \textbf{S}cene\textbf{F}low E\textbf{X}tensible \textbf{M}arkup \textbf{L}anguage \\
%SFTXL & \textbf{S}cene\textbf{F}low \textbf{T}extual E\textbf{X}pression \textbf{L}anguage \\
%SCXML & \textbf{S}tate\textbf{C}hart E\textbf{X}tensible \textbf{M}arkup \textbf{L}anguage \\
%DOM & \textbf{D}ocument \textbf{O}bject \textbf{M}odel \\
%LR & \textbf{L}eft to \textbf{R}ightmost derivation \\
%LALR & \textbf{L}ook\textbf{A}head LR\\
%NPC & \textbf{N}on-\textbf{P}erson-\textbf{C}haracter\\
%ABL & \textbf{A} \textbf{B}ehavior \textbf{L}anguage\\
%\end{longtable}
%\end{center}

%******************************************************************************
% LIST OF FIGURES
%******************************************************************************
\normalfont
\clearpage
\listoffigures

%******************************************************************************
% LIST OF TABLES
%******************************************************************************
\normalfont
\clearpage
\listoftables

%******************************************************************************
% LIST OF ALGORITHMS
%******************************************************************************
%\normalfont
\clearpage
\listofalgorithms

%******************************************************************************
% END DOCUMENT
%******************************************************************************
\end{document}
